{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.7.10",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "colab": {
      "name": "sentiment_analysis PyTorch IMDB.ipynb",
      "provenance": []
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "VO5mlzfdyUbE",
        "trusted": true
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "from torchtext import data, datasets\n",
        "\n",
        "import numpy as np\n",
        "import random\n",
        "\n",
        "import spacy\n",
        "from spacy.tokenizer import Tokenizer\n",
        "\n",
        "from string import punctuation\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r00lm3m_cI3h",
        "trusted": true,
        "outputId": "13512361-7520-4af6-9deb-68ed9a9e0cd3"
      },
      "source": [
        "torch.cuda.is_available()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fSiJmmv7SFHc",
        "trusted": true
      },
      "source": [
        "nlp = spacy.load(\"en_core_web_sm\")\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MaEd1ng-CWgT",
        "trusted": true
      },
      "source": [
        "def tokenize(sentence):\n",
        "    sentence = sentence.lower()\n",
        "    return [tok.text for tok in nlp.tokenizer(sentence) if  \n",
        "            tok.text not in punctuation]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yt9XcGB6yUbU",
        "trusted": true
      },
      "source": [
        "TEXT = data.Field(tokenize=tokenize, include_lengths = True)\n",
        "LABEL = data.LabelField()\n",
        "\n",
        "train_data, test_data = datasets.IMDB.splits(TEXT, LABEL)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QjY4oIAeyUbV",
        "trusted": true
      },
      "source": [
        "train_data, valid_data = train_data.split(split_ratio=0.8, random_state=random.seed(1024))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XUeszlcCyUbX",
        "trusted": true,
        "outputId": "68a64d79-1334-4be0-8b3e-33b57458cc95"
      },
      "source": [
        "print('len_train_data: ', len(train_data))\n",
        "print('len_test_data: ',  len(test_data))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "len_train_data:  20000\n",
            "len_test_data:  25000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w8HkyCJ6yUbX",
        "trusted": true
      },
      "source": [
        "TEXT.build_vocab(train_data, valid_data, \n",
        "                 max_size = 30000,\n",
        "                 vectors = \"glove.6B.300d\",\n",
        "                 unk_init = torch.Tensor.normal_)\n",
        "LABEL.build_vocab(train_data)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2TgarMvU5jwF",
        "trusted": true,
        "outputId": "898fd4d3-cf99-4ca5-e21f-baee221dab3e"
      },
      "source": [
        "TEXT.vocab.vectors"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[-0.5858,  0.5646, -0.5422,  ...,  0.1476, -0.0430, -0.7319],\n",
              "        [-2.0477, -1.3294, -0.3867,  ...,  1.1911, -0.0073,  0.3330],\n",
              "        [ 0.0466,  0.2132, -0.0074,  ...,  0.0091, -0.2099,  0.0539],\n",
              "        ...,\n",
              "        [ 0.6308, -0.8578,  1.0551,  ...,  0.0186,  0.8295, -1.6352],\n",
              "        [-0.1772,  0.4024, -0.3649,  ...,  0.1901,  0.6188,  0.0453],\n",
              "        [-0.0640, -0.1976, -0.6130,  ...,  0.2417, -0.2630, -0.2261]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZMj3oX4GyUbY",
        "trusted": true
      },
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "train_iterator, valid_iterator, test_iterator = data.BucketIterator.splits((train_data, valid_data, test_data),\n",
        "        batch_size = 50,\n",
        "        sort_key = lambda x: len(x.text), sort_within_batch = True,\n",
        "        device = device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "81JHGqt_EnzT",
        "trusted": true
      },
      "source": [
        "import torch.nn as nn\n",
        "from torch.nn.utils.rnn import pack_padded_sequence\n",
        "\n",
        "class Bi_LSTM(nn.Module):\n",
        "  def __init__(self, vocab_size, embedding_size, hidden_size, size2, num_classes, \n",
        "               count_layers, bidirec_, dropout, pad_index):\n",
        "  \n",
        "    super().__init__()\n",
        "\n",
        "    self.embedding  = nn.Embedding(vocab_size, embedding_size, \n",
        "                                  padding_idx=pad_index)\n",
        "    \n",
        "    self.lstm = nn.LSTM(embedding_size, hidden_size,\n",
        "                        num_layers=count_layers,\n",
        "                        bidirectional = bidirec_, dropout = dropout)\n",
        "    \n",
        "    self.dropout = nn.Dropout(dropout)\n",
        "    self.fc = nn.Linear(hidden_size * 2, size2)\n",
        "    self.fc2 = nn.Linear(size2 , num_classes)\n",
        "\n",
        "    self.relu = nn.ReLU()\n",
        "    \n",
        "  def forward(self, text, text_lengths):\n",
        "    new_embedding = self.embedding(text)\n",
        "    packed_embedded = pack_padded_sequence(new_embedding, text_lengths.to('cpu')) \n",
        "    packed_output, (hidden, cell) = self.lstm(packed_embedded)\n",
        "\n",
        "    cat = torch.cat((hidden[-2, :, :], hidden[-1, :, :]), dim=1)\n",
        "    act_f1 = self.relu(cat)\n",
        "    act_f2 = self.fc(act_f1)\n",
        "    act_f3 = self.dropout(act_f2)\n",
        "    act_f4 = self.fc2(act_f3)\n",
        "   \n",
        "    \n",
        "    return act_f4"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ebUvzsxS7f6v",
        "trusted": true
      },
      "source": [
        "embedding_size = 300\n",
        "vocab_size = len(TEXT.vocab)\n",
        "hidden_size = 512\n",
        "size2 = 1024\n",
        "count_layers = 2\n",
        "output_size = 1\n",
        "dropout_keep_prob = 0.5\n",
        "pad_index = TEXT.vocab.stoi[TEXT.pad_token]\n",
        "bidirectional = True"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EJZO4-KURSuA",
        "trusted": true
      },
      "source": [
        " model_lstm = Bi_LSTM(vocab_size=vocab_size, embedding_size=embedding_size, \n",
        "                     hidden_size=hidden_size, size2 = size2, num_classes=output_size, \n",
        "                     count_layers=count_layers, \n",
        "                     bidirec_=bidirectional, dropout=dropout_keep_prob,\n",
        "                     pad_index=pad_index)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fzrx7ow-tUPg",
        "trusted": true
      },
      "source": [
        "import torch.optim as optim\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tHnRscWTRVho",
        "trusted": true
      },
      "source": [
        "optimizer = torch.optim.Adam(model_lstm.parameters())\n",
        "criterion = nn.BCEWithLogitsLoss()\n",
        "\n",
        "model_lstm = model_lstm.to(device)\n",
        "criterion = criterion.to(device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y2HmCvsQYisz",
        "trusted": true
      },
      "source": [
        "import time"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HocvjzilK6Md",
        "trusted": true
      },
      "source": [
        "def train(model, train_iterator, optimazer, criterion):\n",
        "  epoch_loss = 0\n",
        "  epoch_acc = 0\n",
        "  model.train()\n",
        "  start_time = time.time()\n",
        "  for batch in train_iterator:\n",
        "    optimizer.zero_grad()\n",
        "    predictions = model(batch.text[0], batch.text[1]).squeeze(1)\n",
        "\n",
        "    batch_label = batch.label.type_as(predictions)\n",
        "    loss = criterion(predictions, batch_label)\n",
        "    rounded_predictions = torch.round(torch.sigmoid(predictions))\n",
        "    \n",
        "    correct = (rounded_predictions == batch.label).float() \n",
        "    acc = correct.sum()/len(correct)\n",
        "    \n",
        "\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    epoch_loss += loss.item()\n",
        "    epoch_acc += acc.item()\n",
        "\n",
        "  end_time = time.time()\n",
        "  print((end_time - start_time)/60)  \n",
        "\n",
        "  print('loss: ',epoch_loss / len(train_iterator),' accuracy: ' ,epoch_acc / len(train_iterator))\n",
        "  return epoch_loss / len(train_iterator), epoch_acc / len(train_iterator)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dyj2-NMXL_wN",
        "trusted": true
      },
      "source": [
        "def validation(model, valid_iterator, criterion):\n",
        "  epoch_loss_eval = 0\n",
        "  epoch_acc_eval = 0\n",
        "  model.eval()\n",
        "  start_time = time.time()\n",
        "  with torch.no_grad():\n",
        "      for batch in valid_iterator:\n",
        "        predictions = model(batch.text[0], batch.text[1]).squeeze(1)\n",
        "        batch_label = batch.label.type_as(predictions)\n",
        "        loss = criterion(predictions, batch_label)\n",
        "        rounded_predictions = torch.round(torch.sigmoid(predictions))\n",
        "\n",
        "        correct = (rounded_predictions == batch.label).float() \n",
        "        acc = correct.sum()/len(correct)\n",
        "        epoch_loss_eval += loss.item()\n",
        "        epoch_acc_eval += acc.item()\n",
        "  end_time = time.time()\n",
        "  print('time val: ', (end_time - start_time)/60)  \n",
        "  print('loss: ',epoch_loss_eval / len(valid_iterator),' accuracy: ' ,epoch_acc_eval / len(valid_iterator))\n",
        "  return epoch_loss_eval / len(valid_iterator), epoch_acc_eval / len(valid_iterator)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fJOOaCP6RZ4L",
        "trusted": true,
        "outputId": "acd2ae98-7b4f-4f34-864e-aa4948fd4991"
      },
      "source": [
        "best_valid_loss = float('inf')\n",
        "\n",
        "for i in range(7):\n",
        "    print('iteration: ', i+1)\n",
        "  \n",
        "    train_loss, train_acc = train(model_lstm, train_iterator, optimizer,criterion)\n",
        "    valid_loss, valid_acc = validation(model_lstm, valid_iterator, criterion)\n",
        "    if valid_loss < best_valid_loss:\n",
        "            best_valid_loss = valid_loss\n",
        "            torch.save(model_lstm.state_dict(), 'best_model.pt')\n",
        "\n",
        "best_param = model_lstm.load_state_dict(torch.load('best_model.pt'))\n",
        "print('------------------------------')\n",
        "best_result = validation(model_lstm, test_iterator, criterion)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "iteration:  1\n",
            "1.4593804995218913\n",
            "loss:  0.5989452665299178  accuracy:  0.658299982920289\n",
            "time val:  0.10149643421173096\n",
            "loss:  0.40505763605237005  accuracy:  0.8153999769687652\n",
            "iteration:  2\n",
            "1.4596008698145548\n",
            "loss:  0.30653180098161104  accuracy:  0.8706499746441841\n",
            "time val:  0.10154728492101034\n",
            "loss:  0.3358109851181507  accuracy:  0.8541999745368958\n",
            "iteration:  3\n",
            "1.455478568871816\n",
            "loss:  0.17482712886296212  accuracy:  0.9321999773383141\n",
            "time val:  0.10103125174840291\n",
            "loss:  0.28466768652200697  accuracy:  0.8977999758720397\n",
            "iteration:  4\n",
            "1.4581735452016196\n",
            "loss:  0.0863478634157218  accuracy:  0.9698999781906604\n",
            "time val:  0.10168864727020263\n",
            "loss:  0.3515908346325159  accuracy:  0.8965999794006347\n",
            "iteration:  5\n",
            "1.4620246569315591\n",
            "loss:  0.041697045281471216  accuracy:  0.986299983561039\n",
            "time val:  0.10099232196807861\n",
            "loss:  0.43550104297697545  accuracy:  0.8939999747276306\n",
            "iteration:  6\n",
            "1.4592486262321471\n",
            "loss:  0.029849791722081135  accuracy:  0.9894499859213829\n",
            "time val:  0.1002921223640442\n",
            "loss:  0.49689725071191787  accuracy:  0.8919999760389328\n",
            "iteration:  7\n",
            "1.456999413172404\n",
            "loss:  0.01704028513060621  accuracy:  0.994199990928173\n",
            "time val:  0.10354063908259074\n",
            "loss:  0.5622087174654007  accuracy:  0.8951999753713608\n",
            "------------------------------\n",
            "time val:  0.48129015366236366\n",
            "loss:  0.29198733147233724  accuracy:  0.8871199742555619\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "y3CmlZAeYOmm",
        "outputId": "5f6f1cb8-085b-472f-fda9-6188ac0e5126"
      },
      "source": [
        "model_lstm.state_dict()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "OrderedDict([('embedding.weight',\n",
              "              tensor([[ 2.5999,  0.3954, -1.6498,  ..., -1.2378,  0.2920,  0.3005],\n",
              "                      [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
              "                      [ 0.4090,  0.5958,  0.6855,  ..., -0.5204,  0.3533,  0.2377],\n",
              "                      ...,\n",
              "                      [-0.0890, -0.4436, -2.3261,  ..., -0.1895, -0.0114,  0.6668],\n",
              "                      [ 1.0576,  1.1353,  0.3472,  ...,  1.8292,  1.7474,  0.7690],\n",
              "                      [ 1.6179,  0.0929, -0.3723,  ..., -1.6484, -0.2116, -0.3492]],\n",
              "                     device='cuda:0')),\n",
              "             ('lstm.weight_ih_l0',\n",
              "              tensor([[-0.0918,  0.0313,  0.0592,  ...,  0.0040, -0.0879, -0.0878],\n",
              "                      [ 0.0695, -0.0316,  0.0077,  ..., -0.0801, -0.0030, -0.0942],\n",
              "                      [-0.0128, -0.0061,  0.0222,  ...,  0.0451,  0.0513,  0.0483],\n",
              "                      ...,\n",
              "                      [ 0.0286, -0.0383, -0.0487,  ...,  0.0141, -0.1381, -0.0280],\n",
              "                      [-0.0383, -0.0111, -0.0234,  ..., -0.0157,  0.0571, -0.0680],\n",
              "                      [-0.0215, -0.0728,  0.0075,  ..., -0.0358,  0.0660, -0.0236]],\n",
              "                     device='cuda:0')),\n",
              "             ('lstm.weight_hh_l0',\n",
              "              tensor([[-0.1644,  0.1290, -0.0347,  ...,  0.0054, -0.0346, -0.0257],\n",
              "                      [-0.0616,  0.0722, -0.0214,  ...,  0.0425, -0.0010,  0.0205],\n",
              "                      [-0.0455,  0.0366,  0.0198,  ...,  0.0703,  0.0444, -0.1108],\n",
              "                      ...,\n",
              "                      [ 0.0467, -0.0786,  0.0052,  ...,  0.0151,  0.0051, -0.0387],\n",
              "                      [-0.0321,  0.0702, -0.0752,  ...,  0.0300, -0.0038, -0.0043],\n",
              "                      [-0.0020,  0.0359, -0.0049,  ..., -0.0033, -0.0334, -0.0253]],\n",
              "                     device='cuda:0')),\n",
              "             ('lstm.bias_ih_l0',\n",
              "              tensor([-0.0578,  0.0090, -0.1066,  ..., -0.0580, -0.0729,  0.0170],\n",
              "                     device='cuda:0')),\n",
              "             ('lstm.bias_hh_l0',\n",
              "              tensor([-3.6410e-02, -5.5317e-05, -7.5135e-02,  ..., -6.3002e-02,\n",
              "                      -3.9362e-02, -3.9028e-02], device='cuda:0')),\n",
              "             ('lstm.weight_ih_l0_reverse',\n",
              "              tensor([[-0.0392,  0.0701,  0.0339,  ...,  0.0069, -0.0382,  0.0322],\n",
              "                      [ 0.0290, -0.0493,  0.0054,  ...,  0.0593, -0.0084, -0.0083],\n",
              "                      [ 0.0376, -0.0141, -0.0360,  ..., -0.0265, -0.0112,  0.0601],\n",
              "                      ...,\n",
              "                      [ 0.0160,  0.0531,  0.0351,  ...,  0.1022, -0.0343, -0.0379],\n",
              "                      [-0.0840, -0.0345,  0.0464,  ...,  0.0329, -0.0348,  0.0276],\n",
              "                      [-0.0762,  0.0506,  0.0118,  ..., -0.0183,  0.0141,  0.0145]],\n",
              "                     device='cuda:0')),\n",
              "             ('lstm.weight_hh_l0_reverse',\n",
              "              tensor([[-5.1613e-02, -4.1967e-02, -8.0904e-02,  ...,  4.6008e-02,\n",
              "                       -1.5084e-02,  3.1577e-04],\n",
              "                      [ 5.3226e-03,  6.7508e-02,  6.5064e-02,  ..., -7.4838e-02,\n",
              "                       -3.3147e-02, -3.7547e-02],\n",
              "                      [ 4.3496e-03,  2.4308e-02,  5.2758e-02,  ...,  4.1703e-02,\n",
              "                       -3.9777e-02,  3.1150e-02],\n",
              "                      ...,\n",
              "                      [-1.9756e-02, -6.5247e-02,  5.5596e-02,  ..., -1.1498e-02,\n",
              "                       -2.7842e-02, -4.2131e-03],\n",
              "                      [ 3.1085e-02, -7.8201e-03,  1.7528e-02,  ..., -3.3146e-02,\n",
              "                        1.0577e-02, -6.3911e-05],\n",
              "                      [-2.1774e-02, -7.9680e-02,  3.7525e-03,  ...,  3.0477e-03,\n",
              "                       -2.1141e-02, -2.9961e-02]], device='cuda:0')),\n",
              "             ('lstm.bias_ih_l0_reverse',\n",
              "              tensor([-0.0490, -0.0578, -0.0457,  ..., -0.0831, -0.0383, -0.0155],\n",
              "                     device='cuda:0')),\n",
              "             ('lstm.bias_hh_l0_reverse',\n",
              "              tensor([-0.1124, -0.0389, -0.0477,  ..., -0.1159, -0.0932, -0.0357],\n",
              "                     device='cuda:0')),\n",
              "             ('lstm.weight_ih_l1',\n",
              "              tensor([[ 0.0571,  0.0151, -0.0093,  ..., -0.0282,  0.0769,  0.0009],\n",
              "                      [ 0.0230, -0.0829, -0.0301,  ...,  0.0019, -0.0238,  0.0786],\n",
              "                      [ 0.0088, -0.0132, -0.0155,  ...,  0.0027, -0.0146,  0.0277],\n",
              "                      ...,\n",
              "                      [ 0.1623, -0.0606, -0.0299,  ..., -0.0699, -0.1136, -0.0522],\n",
              "                      [ 0.0044,  0.0350,  0.0433,  ..., -0.0055,  0.0219,  0.0066],\n",
              "                      [-0.0108, -0.0327, -0.0484,  ..., -0.0347,  0.0034,  0.0315]],\n",
              "                     device='cuda:0')),\n",
              "             ('lstm.weight_hh_l1',\n",
              "              tensor([[-0.0430, -0.0275,  0.0635,  ..., -0.0139, -0.0074, -0.0424],\n",
              "                      [ 0.0144, -0.0791, -0.0461,  ...,  0.0153,  0.0276,  0.0029],\n",
              "                      [ 0.0724, -0.0175, -0.0359,  ...,  0.0107, -0.0025,  0.0046],\n",
              "                      ...,\n",
              "                      [-0.0629,  0.0181,  0.0224,  ..., -0.0673,  0.0068, -0.0271],\n",
              "                      [-0.0212, -0.0481, -0.0423,  ...,  0.0435, -0.0222,  0.0020],\n",
              "                      [-0.0182,  0.0274,  0.0093,  ...,  0.0626, -0.0318, -0.0027]],\n",
              "                     device='cuda:0')),\n",
              "             ('lstm.bias_ih_l1',\n",
              "              tensor([-0.0158, -0.0710,  0.0025,  ...,  0.0197, -0.1012, -0.0628],\n",
              "                     device='cuda:0')),\n",
              "             ('lstm.bias_hh_l1',\n",
              "              tensor([-0.0263, -0.0232, -0.0174,  ..., -0.0084, -0.1026, -0.0692],\n",
              "                     device='cuda:0')),\n",
              "             ('lstm.weight_ih_l1_reverse',\n",
              "              tensor([[ 0.0416,  0.0156,  0.0100,  ..., -0.0193, -0.0012, -0.0026],\n",
              "                      [-0.0340, -0.0023, -0.0401,  ..., -0.0109,  0.0075,  0.0750],\n",
              "                      [ 0.0143, -0.0290,  0.0514,  ...,  0.0312, -0.0495,  0.0243],\n",
              "                      ...,\n",
              "                      [-0.0408,  0.0428,  0.0440,  ...,  0.0298, -0.0473,  0.0257],\n",
              "                      [-0.0448, -0.0325,  0.0317,  ...,  0.0551, -0.0399, -0.0160],\n",
              "                      [ 0.0466,  0.0428, -0.0042,  ...,  0.0082, -0.0305, -0.0426]],\n",
              "                     device='cuda:0')),\n",
              "             ('lstm.weight_hh_l1_reverse',\n",
              "              tensor([[-0.0621, -0.0418, -0.0425,  ..., -0.0091,  0.0676, -0.0124],\n",
              "                      [-0.0569, -0.0072, -0.0106,  ..., -0.0180,  0.0297,  0.0241],\n",
              "                      [-0.0574,  0.0249, -0.0231,  ..., -0.0233,  0.0715,  0.0433],\n",
              "                      ...,\n",
              "                      [ 0.0296,  0.0225,  0.0330,  ..., -0.0292,  0.0312,  0.0423],\n",
              "                      [ 0.0274, -0.0081, -0.0051,  ...,  0.0456,  0.0030,  0.0704],\n",
              "                      [-0.0086,  0.0126, -0.0352,  ...,  0.0386, -0.0134, -0.0521]],\n",
              "                     device='cuda:0')),\n",
              "             ('lstm.bias_ih_l1_reverse',\n",
              "              tensor([-0.0440, -0.0370, -0.0506,  ..., -0.0575, -0.0676, -0.0236],\n",
              "                     device='cuda:0')),\n",
              "             ('lstm.bias_hh_l1_reverse',\n",
              "              tensor([-0.0820, -0.0565, -0.0529,  ..., -0.0552, -0.0511, -0.0295],\n",
              "                     device='cuda:0')),\n",
              "             ('fc.weight',\n",
              "              tensor([[ 0.0221, -0.0501, -0.0045,  ..., -0.0028,  0.0155, -0.0321],\n",
              "                      [-0.0193,  0.0108,  0.0197,  ..., -0.0044,  0.0136,  0.0277],\n",
              "                      [-0.0115, -0.0198,  0.0210,  ..., -0.0323, -0.0054, -0.0045],\n",
              "                      ...,\n",
              "                      [ 0.0194, -0.0109,  0.0172,  ...,  0.0455, -0.0287,  0.0143],\n",
              "                      [-0.0173, -0.0009, -0.0075,  ..., -0.0050,  0.0221, -0.0057],\n",
              "                      [-0.0092,  0.0435, -0.0281,  ..., -0.0144, -0.0150, -0.0390]],\n",
              "                     device='cuda:0')),\n",
              "             ('fc.bias',\n",
              "              tensor([ 0.0009,  0.0156, -0.0246,  ..., -0.0277, -0.0135,  0.0268],\n",
              "                     device='cuda:0')),\n",
              "             ('fc2.weight',\n",
              "              tensor([[ 0.0177,  0.0017, -0.0063,  ...,  0.0014,  0.0013, -0.0011]],\n",
              "                     device='cuda:0')),\n",
              "             ('fc2.bias', tensor([-0.0296], device='cuda:0'))])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qiIDSb4OYOmm"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5vRzL3QBieem"
      },
      "source": [
        "Файл з state_dict можна завантажити з гугл диску, перейшовши за наступним посиланням:\n",
        "https://drive.google.com/file/d/1odJqGOytlxDNlA360Sud2TZX4vQ_NW4Y/view?usp=sharing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2sxpo1Cfi6Ds"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}